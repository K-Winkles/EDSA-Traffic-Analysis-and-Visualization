{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Extraction using Beautiful Soup\n",
    "def data_extraction():\n",
    "    #Libraries For Data Extraction\n",
    "    from bs4 import BeautifulSoup\n",
    "    import time\n",
    "    import datetime\n",
    "    from selenium.webdriver.support.ui import WebDriverWait\n",
    "    from selenium.webdriver.support import expected_conditions as EC\n",
    "    from selenium.webdriver.common.by import By\n",
    "    from selenium import webdriver\n",
    "    \n",
    "    #specify the url\n",
    "    url = 'http://mmdatraffic.interaksyon.com/line-view-edsa.php'\n",
    "    \n",
    "    # Start the WebDriver and load the page\n",
    "    wd = webdriver.Firefox()\n",
    "    wd.get(url)\n",
    "\n",
    "    # Wait for the dynamically loaded elements to show up\n",
    "    WebDriverWait(wd, 10).until(\n",
    "        EC.visibility_of_element_located((By.CLASS_NAME, \"line-col\")))\n",
    "\n",
    "    # And grab the page HTML source\n",
    "    html_page = wd.page_source\n",
    "    wd.quit()\n",
    "\n",
    "    # Now you can use html_page as you like\n",
    "    from bs4 import BeautifulSoup\n",
    "    soup = BeautifulSoup(html_page)\n",
    "\n",
    "    #set time stamp.\n",
    "    ts = time.time()\n",
    "    timestamp = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d_%H_%M_%S')\n",
    "    stringdata = \"TIMESTAMP: \"+ str(timestamp)+\"\\n\"+\"\\n\"\n",
    "\n",
    "    #extract name of lines\n",
    "    list_of_names_html=soup.find_all('div',{'class':'line-name'})\n",
    "    list_of_names = []\n",
    "\n",
    "    for children in list_of_names_html:\n",
    "        grandchildren = children.findChild(\"p\")\n",
    "        temp = grandchildren.get_text(separator=' ')\n",
    "        temp = temp.split(' ')\n",
    "        list_of_names.append(temp[0]) #NOTE: fix string separation\n",
    "    list_of_names.pop(0) \n",
    "\n",
    "    #extract southbound/northbound volume\n",
    "    list_of_volume_html=soup.find_all('div',{'class':'line-status'})\n",
    "    list_of_southbound = []\n",
    "    list_of_northbound = []\n",
    "\n",
    "    i=1\n",
    "    for children in list_of_volume_html:\n",
    "        temp = children.text\n",
    "        temp = temp.split()\n",
    "\n",
    "        if(temp[1]==\"LIGHT\"):\n",
    "            temp[1]=0\n",
    "        elif(temp[1]==\"MODERATE\"):\n",
    "            temp[1]=1\n",
    "        elif(temp[1]==\"HEAVY\"):\n",
    "            temp[1]=2\n",
    "\n",
    "        if(i%2 == 0):\n",
    "            list_of_northbound.append(temp[1])\n",
    "        else:\n",
    "            list_of_southbound.append(temp[1])\n",
    "\n",
    "        i=i+1\n",
    "\n",
    "    #save data into one variable\n",
    "    for i in range(len(list_of_names)):\n",
    "        stringdata = stringdata + '{:>12}  {:>12}  {:>12}'.format(list_of_names[i], str(list_of_southbound[i]), str(list_of_northbound[i])) + \"\\n\"\n",
    "    \n",
    "    #Save raw data into csv file\n",
    "    filename = \"rawdata_\"+ str(timestamp)+\".csv\"\n",
    "    file = open(filename,\"a\")\n",
    "    file.write(stringdata)   \n",
    "    file.close()\n",
    "    \n",
    "    #return list containing data lists\n",
    "    list_of_lists = [list_of_names, list_of_southbound, list_of_northbound, timestamp]\n",
    "    return list_of_lists"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
