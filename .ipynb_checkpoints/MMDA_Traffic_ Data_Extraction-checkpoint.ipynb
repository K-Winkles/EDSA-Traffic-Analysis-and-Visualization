{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDSA Traffic Analysis and Visualization: Extraction\n",
    "This script is in charge of extracting sufficient data. It is important to define the target_runs variable since this dictates the timeframe in which data will be extracted. Since the MMDA website live updates every 15 minutes, then the script must run accordingly.\n",
    "\n",
    "The following libraries were imported:\n",
    "* For scheduling\n",
    "    1. schedule - used to track the runtime of the script and to prompt extraction at 15 minute intervals\n",
    "    2. time - used to take note of the time stamp.\n",
    "    3. datetime - used to format time.\n",
    "    4. os, os.path - used to count the amount of extracted files which will determine if the target number of runs has been reached.\n",
    "    5. exit (from sys) - used to stop script termination once the target number of runs has been achieved.\n",
    "\n",
    "Technically, the interval in which the script extracts data from the MMDA website is flexible. Hence, the same script can be used for other scraping tasks. \n",
    "\n",
    "* For visualization\n",
    "    1. numpy - in particular, numpy arrays were used for its flexibility.\n",
    "    2. matplotlib - this is a powerful and reliable visualization tool. \n",
    "\n",
    "* For Data Extraction\n",
    "    1. BeautifulSoup - used to process html data. \n",
    "    2. various selenium sublibraries - this was used to extract DYNAMIC web content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define constants here\n",
    "global target_runs\n",
    "global interval\n",
    "\n",
    "target_runs = 672 #7 days\n",
    "interval = 15 # in MINUTES\n",
    "\n",
    "#Libraries For Scheduling\n",
    "import schedule\n",
    "import time\n",
    "import datetime\n",
    "import os, os.path \n",
    "from sys import exit\n",
    "\n",
    "#Libraries for visualization\n",
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "#Libraries For Data Extraction\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import WebDriverException   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Extraction\n",
    "The flow is as follows:\n",
    "1. The webdriver from selenium will load the page in question. Of course, the url must first be specified. Note that to use webdriver, the appropriate driver must be installed. This has to be done in accordance to the browser being used. For example, Mozilla Firefox uses geckodriver, Google Chrome uses chromedriver, etc.\n",
    "2. Once the dynamic web content has been extracted, the data can now be processed using Beautiful Soup. The appropriate data will be extracted according to the webpage's html structure. \n",
    "3. Finally, after some pre-processing, the data is ready to be written to a .csv file and used for visualization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_extraction():\n",
    "    #specify the url\n",
    "    url = 'http://mmdatraffic.interaksyon.com/line-view-edsa.php'\n",
    "    \n",
    "    # Start the WebDriver and load the page\n",
    "    wd = webdriver.Firefox()\n",
    "    wd.get(url)\n",
    "\n",
    "    # Wait for the dynamically loaded elements to show up\n",
    "    WebDriverWait(wd, 10).until(\n",
    "        EC.visibility_of_element_located((By.CLASS_NAME, \"line-col\")))\n",
    "\n",
    "    # And grab the page HTML source\n",
    "    html_page = wd.page_source\n",
    "    wd.quit()\n",
    "\n",
    "    # Now you can use html_page as you like\n",
    "    soup = BeautifulSoup(html_page)\n",
    "    \n",
    "    #set time stamp.\n",
    "    ts = time.time()\n",
    "    timestamp = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d_%H_%M_%S')\n",
    "    stringdata = \"TIMESTAMP: \"+ str(timestamp)+\"\\n\"+\"\\n\"\n",
    "\n",
    "    #extract name of lines\n",
    "    list_of_names_html=soup.find_all('div',{'class':'line-name'})\n",
    "    list_of_names = []\n",
    "    \n",
    "\n",
    "    for children in list_of_names_html:\n",
    "        grandchildren = children.findChild(\"p\")\n",
    "        temp = grandchildren.get_text(separator=' ')\n",
    "        temp = temp.split(' ')\n",
    "        list_of_names.append(temp[0])\n",
    "    list_of_names.pop(0) \n",
    "    \n",
    "    #extract southbound/northbound volume\n",
    "    list_of_volume_html=soup.find_all('div',{'class':'line-status'})\n",
    "    list_of_southbound = []\n",
    "    list_of_northbound = []\n",
    "\n",
    "    i=1\n",
    "    for children in list_of_volume_html:\n",
    "        temp = children.text\n",
    "        temp = temp.split()\n",
    "\n",
    "        if(temp[1]==\"LIGHT\"):\n",
    "            temp[1]=0\n",
    "        elif(temp[1]==\"MODERATE\"):\n",
    "            temp[1]=1\n",
    "        elif(temp[1]==\"HEAVY\"):\n",
    "            temp[1]=2\n",
    "        elif(temp[1]==\"NO\"):\n",
    "            temp[1]=0 # Place holder first\n",
    "\n",
    "        if(i%2 == 0):\n",
    "            list_of_northbound.append(temp[1])\n",
    "        else:\n",
    "            list_of_southbound.append(temp[1])\n",
    "\n",
    "        i=i+1\n",
    "        \n",
    "    #save data into one variable\n",
    "    for i in range(len(list_of_names)):\n",
    "        stringdata = stringdata + '{:>12}  {:>12}  {:>12}'.format(list_of_names[i], str(list_of_southbound[i]), str(list_of_northbound[i])) + \"\\n\"\n",
    "    \n",
    "    #Save raw data into csv file\n",
    "    filename = \"rawdata_\"+ str(timestamp)+\".csv\"\n",
    "    file = open(filename,\"a\")\n",
    "    file.write(stringdata)   \n",
    "    file.close()\n",
    "\n",
    "    #return list containing data lists\n",
    "    list_of_lists = [list_of_names, list_of_southbound, list_of_northbound, timestamp]\n",
    "    return list_of_lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization using Matplotlib\n",
    "def visualize_overall(list_of_names, list_of_southbound, list_of_northbound,timestamp):\n",
    "    #Visualize overall EDSA traffic at certain timestamp\n",
    "    roadnum = range(0,len(list_of_names))\n",
    "   \n",
    "    plt.scatter(roadnum, list_of_southbound, label=\"SOUTHBOUND\", color=\"g\",marker = \"s\")\n",
    "    plt.scatter(roadnum, list_of_northbound, label = \"NORTHBOUND\", color = \"m\",marker = \"|\")\n",
    "\n",
    "    plt.xlabel(\"Road\")\n",
    "    plt.ylabel(\"Volume\")\n",
    "\n",
    "    plt.title(label=\"EDSA TRAFFIC: \"+timestamp)\n",
    "    plt.legend(bbox_to_anchor=(0, 1), loc='lower center', ncol=1)\n",
    "    plt.savefig(\"EDSA TRAFFIC \"+timestamp+\".png\") #finally, save the figure  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def job():\n",
    "    try: # In case of power/network interruption, keep running      \n",
    "        #extract data at current time stamp\n",
    "        list_of_lists = data_extraction()\n",
    "\n",
    "        #visualize overall data.\n",
    "        visualize_overall(list_of_lists[0],list_of_lists[1],list_of_lists[2],list_of_lists[3])\n",
    "\n",
    "        #track number of runs.\n",
    "        num_of_runs = (len([file for file in os.listdir('.') if file.endswith('.png')]))\n",
    "        print(\"Run number \" + str(num_of_runs))\n",
    "\n",
    "        #if target of runs has been reached, visualize individual data.\n",
    "        if (num_of_runs == target_runs):\n",
    "            exit(0) #exit program!\n",
    "    except WebDriverException:\n",
    "        pass  \n",
    "\n",
    "schedule.every(0.1).minutes.do(job)\n",
    "while 1:\n",
    "    schedule.run_pending()\n",
    "    time.sleep(1) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
